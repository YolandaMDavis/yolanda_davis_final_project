{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3849, 26)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data into dataframe\n",
    "filepath = 'assets/nifi_prometheus_metrics.csv'\n",
    "nifi_metrics = pd.read_csv(filepath)\n",
    "\n",
    "# Remove unused id and clean up column names \n",
    "nifi_metrics = nifi_metrics.drop('id',axis=1)\n",
    "updated_columns = [labels.split(':')[0] for labels in nifi_metrics.columns.values]\n",
    "updated_columns = np.array(updated_columns)\n",
    "nifi_metrics.columns=updated_columns\n",
    "nifi_metrics = nifi_metrics.set_index('time')\n",
    "nifi_metrics = nifi_metrics.drop(['timestamp'],axis=1)\n",
    "\n",
    "#Add Datetime as a feature (did not get to do this in part 1)\n",
    "#convert index to datetime\n",
    "nifi_metrics.index = pd.to_datetime(nifi_metrics.index)\n",
    "\n",
    "#convert datetime to features columns\n",
    "nifi_metrics.loc[:,'hour_of_day'] = nifi_metrics.index.hour \n",
    "nifi_metrics.loc[:,'day_of_week'] = nifi_metrics.index.weekday_name\n",
    "\n",
    "#Confirm Shape\n",
    "nifi_metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3849 entries, 2019-07-20 18:15:00 to 2019-07-27 17:00:00\n",
      "Data columns (total 26 columns):\n",
      "ActiveThreads                    3849 non-null float64\n",
      "BytesQueued                      3849 non-null float64\n",
      "BytesReadLast5Minutes            3849 non-null float64\n",
      "BytesReceivedLast5Minutes        3849 non-null float64\n",
      "BytesSentLast5Minutes            3849 non-null float64\n",
      "BytesWrittenLast5Minutes         3849 non-null float64\n",
      "FlowFilesQueued                  3849 non-null float64\n",
      "FlowFilesReceivedLast5Minutes    3849 non-null float64\n",
      "FlowFilesSentLast5Minutes        3849 non-null float64\n",
      "TotalTaskDurationNanoSeconds     3849 non-null float64\n",
      "TotalTaskDurationSeconds         3849 non-null float64\n",
      "availableCores                   3849 non-null float64\n",
      "jvmdaemon_thread_count           3849 non-null float64\n",
      "jvmfile_descriptor_usage         3849 non-null float64\n",
      "jvmheap_usage                    3849 non-null float64\n",
      "jvmheap_used                     3849 non-null float64\n",
      "jvmnon_heap_usage                3849 non-null float64\n",
      "jvmthread_count                  3849 non-null float64\n",
      "jvmthread_statesblocked          3849 non-null float64\n",
      "jvmthread_statesrunnable         3849 non-null float64\n",
      "jvmthread_statesterminated       3849 non-null float64\n",
      "jvmthread_statestimed_waiting    3849 non-null float64\n",
      "jvmuptime                        3849 non-null float64\n",
      "loadAverage1min                  3849 non-null float64\n",
      "hour_of_day                      3849 non-null int64\n",
      "day_of_week                      3849 non-null object\n",
      "dtypes: float64(24), int64(1), object(1)\n",
      "memory usage: 811.9+ KB\n"
     ]
    }
   ],
   "source": [
    "nifi_metrics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my results from EDA I want to attempt the following\n",
    "\n",
    "1) Try non-linear models with Linear Regression\n",
    "\n",
    "2) Perform cross-validation with KFold for training and test splits\n",
    "\n",
    "3) Break out hour of day feature into dummy variables and assess (via correlation) if those are worth including\n",
    "\n",
    "4) Attempt Random Forest Regressor for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(1,21)\n",
    "\n",
    "#Create features and target columns\n",
    "feature_cols = ['ActiveThreads', 'BytesReceivedLast5Minutes', 'jvmthread_count', 'loadAverage1min']\n",
    "target_col = 'jvmheap_used'\n",
    "\n",
    "# Create feature and target dataframes\n",
    "X = nifi_metrics.loc[:, feature_cols]\n",
    "y = nifi_metrics.loc[:, target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def neg_rmse(y_true, y_pred):\n",
    "    mse = np.square(y_true - y_pred).mean()\n",
    "    return -np.sqrt(mse)\n",
    "\n",
    "#negative because higher is bettter which is what GridSearch expects\n",
    "neg_rmse = make_scorer(neg_rmse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE Heap Used in Megabytes: [-59.22573848]\n",
      "Test RMSE Heap Used in Megabytes: [-59.62779418]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pf = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "pf.fit(X)\n",
    "X_poly = pf.transform(X) \n",
    "\n",
    "kf = KFold(5, shuffle=True)\n",
    "lr_grid = GridSearchCV(estimator=LinearRegression(), param_grid={}, cv=kf, return_train_score=True, scoring=neg_rmse)\n",
    "lr_grid.fit(X_poly,y)\n",
    "\n",
    "results = lr_grid.cv_results_\n",
    "print(\"Training RMSE Heap Used in Megabytes:\", results['mean_train_score'] *.000001)\n",
    "print(\"Test RMSE Heap Used in Megabytes:\",  results['mean_test_score'] * .000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE Heap Used in Megabytes: [-72.81212163 -59.3218767  -56.22830041 -53.70257416 -52.33567266\n",
      " -50.91937849 -49.5451993  -48.11579355 -46.60496855 -45.02152771\n",
      " -43.36682747 -41.64662426 -39.87937131 -38.08190155 -36.30876127\n",
      " -34.5820574  -32.90909369 -31.33582418 -29.8937224  -28.58314063]\n",
      "Test RMSE Heap Used in Megabytes: [-72.97515269 -59.83731214 -57.11737073 -55.28535474 -54.93851037\n",
      " -54.83616557 -54.77755662 -54.80696964 -54.90962024 -54.925478\n",
      " -55.06431348 -55.21645367 -55.33268485 -55.49255281 -55.62035468\n",
      " -55.7903402  -55.96029017 -56.17822334 -56.31876997 -56.52389304]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "feature_cols = ['ActiveThreads', 'BytesReceivedLast5Minutes', 'jvmthread_count', 'loadAverage1min']\n",
    "target_col = 'jvmheap_used'\n",
    "\n",
    "# Create feature and target dataframes\n",
    "X = nifi_metrics.loc[:, feature_cols]\n",
    "y = nifi_metrics.loc[:, target_col]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "kf = KFold(10, shuffle=True)\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid={'max_depth': max_depth_range}, cv=kf, return_train_score=True, scoring=neg_rmse)\n",
    "rf_grid.fit(X_poly,y)\n",
    "results = rf_grid.cv_results_\n",
    "print(\"Training RMSE Heap Used in Megabytes:\", results['mean_train_score'] *.000001)\n",
    "print(\"Test RMSE Heap Used in Megabytes:\",  results['mean_test_score'] * .000001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let see if we have further improvements with hour of day, day of week\n",
    "nifi_metrics = pd.get_dummies(nifi_metrics,columns=['hour_of_day'], drop_first=True)\n",
    "time_cols = [col for col in nifi_metrics.columns if col.startswith(('hour'))]\n",
    "\n",
    "nifi_metrics = pd.get_dummies(nifi_metrics,columns=['day_of_week'], drop_first=True)\n",
    "day_cols = [col for col in day_metrics.columns if col.startswith(('day_of_week'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE Heap Used in Megabytes: [54.59220434]\n",
      "Test RMSE Heap Used in Megabytes: [57.95049631]\n"
     ]
    }
   ],
   "source": [
    "time_feature_cols = time_cols + feature_cols\n",
    "target_col = 'jvmheap_used'\n",
    "\n",
    "# Create feature and target dataframes\n",
    "X = nifi_metrics.loc[:, time_feature_cols]\n",
    "y = nifi_metrics.loc[:, target_col]\n",
    "\n",
    "pf = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "pf.fit(X)\n",
    "X_poly = pf.transform(X) \n",
    "\n",
    "kf = KFold(5, shuffle=True)\n",
    "lr_grid = GridSearchCV(estimator=LinearRegression(), param_grid={}, cv=kf, return_train_score=True, scoring=neg_rmse)\n",
    "lr_grid.fit(X_poly,y)\n",
    "\n",
    "results = lr_grid.cv_results_\n",
    "print(\"Training RMSE Heap Used in Megabytes:\", results['mean_train_score'] *.000001)\n",
    "print(\"Test RMSE Heap Used in Megabytes:\",  results['mean_test_score'] * .000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE Heap Used in Megabytes: [20.53579628]\n",
      "Test RMSE Heap Used in Megabytes: [54.74764017]\n"
     ]
    }
   ],
   "source": [
    "time_feature_cols = time_cols + feature_cols\n",
    "target_col = 'jvmheap_used'\n",
    "\n",
    "# Create feature and target dataframes\n",
    "X = nifi_metrics.loc[:, time_feature_cols]\n",
    "y = nifi_metrics.loc[:, target_col]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 1)\n",
    "kf = KFold(10, shuffle=True)\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid={'max_depth': max_depth_range}, cv=kf, return_train_score=True, scoring=neg_rmse)\n",
    "rf_grid.fit(X_poly,y)\n",
    "results = rf_grid.cv_results_\n",
    "print(\"Training RMSE Heap Used in Megabytes:\", results['mean_train_score'] *.000001)\n",
    "print(\"Test RMSE Heap Used in Megabytes:\",  results['mean_test_score'] * .000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (welcome_to_data_science)",
   "language": "python",
   "name": "pycharm-27ca0870"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
